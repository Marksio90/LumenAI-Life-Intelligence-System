# âš¡ LumenAI - Quick Start Guide

Najprostszy sposÃ³b na uruchomienie LumenAI w 5 minut!

## ğŸ Dla Data Scientists / ML Developers

**JeÅ›li wolisz Pythona i chcesz eksperymentowaÄ‡ z ML:**

```bash
# 1. Sklonuj repo
git clone <repo-url>
cd LumenAI-Life-Intelligence-System

# 2. Automatyczna instalacja Mamba + Å›rodowisko
make mamba-setup

# 3. Dodaj API key
cp .env.example .env
# Edytuj .env i dodaj OPENAI_API_KEY lub ANTHROPIC_API_KEY

# 4. Uruchom (w 2 terminalach)
mamba activate lumenai
make backend-dev

# W drugim terminalu:
make frontend-dev
```

**Gotowe! â†’ http://localhost:3000** ğŸ‰

---

## ğŸ³ Dla Wszystkich Innych

**NajÅ‚atwiejszy sposÃ³b - Docker (zero konfiguracji):**

```bash
# 1. Sklonuj repo
git clone <repo-url>
cd LumenAI-Life-Intelligence-System

# 2. Uruchom setup script
./start.sh

# Lub manualnie:
cp .env.example .env
# Dodaj API keys do .env
docker-compose up --build
```

**Gotowe! â†’ http://localhost:3000** ğŸ‰

---

## ğŸ“‹ Checklist

- [ ] Git zainstalowany
- [ ] Python 3.11+ LUB Docker
- [ ] Node.js 20+ (dla frontend dev)
- [ ] API key (OpenAI lub Anthropic)
- [ ] 5-10 GB wolnego miejsca

## ğŸ†˜ Problemy?

**Backend nie startuje:**
```bash
# SprawdÅº logi
docker-compose logs backend
# Lub jeÅ›li Mamba:
mamba activate lumenai && cd backend && python gateway/main.py
```

**Frontend nie Å‚Ä…czy siÄ™:**
- SprawdÅº czy backend dziaÅ‚a: http://localhost:8000/health
- SprawdÅº .env czy NEXT_PUBLIC_API_URL jest poprawny

**Mamba nie dziaÅ‚a:**
```bash
# Reinstall
make mamba-setup
```

## ğŸ“š Co dalej?

1. **Eksperymentuj** - WyprÃ³buj rÃ³Å¼ne pytania do agentÃ³w
2. **Czytaj docs** - [GETTING_STARTED.md](./docs/GETTING_STARTED.md)
3. **Rozwijaj** - Dodaj wÅ‚asnego agenta
4. **Deploy** - [DEPLOYMENT.md](./docs/DEPLOYMENT.md)

---

**WiÄ™cej info:**
- ğŸ“– [Full Documentation](./docs/)
- ğŸ [Mamba Setup](./docs/MAMBA_SETUP.md)
- ğŸ—ï¸ [Architecture](./docs/ARCHITECTURE.md)

MiÅ‚ego kodowania z LumenAI! ğŸŒŸ
