"""
LumenAI Gateway - Main FastAPI Application
WebSocket-enabled real-time AI assistant gateway
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
from loguru import logger
import sys
from typing import Dict, List

# Add parent directory to path
sys.path.append('..')

from backend.shared.config.settings import settings
from backend.core.orchestrator import Orchestrator
from backend.core.memory import MemoryManager
from backend.services.mongodb_service import init_mongodb_service, get_mongodb_service
from backend.services.chromadb_service import init_chromadb_service, get_chromadb_service
from backend.services.embedding_service import init_embedding_service, get_embedding_service
from backend.services.analytics_service import init_analytics_service, get_analytics_service
from backend.ml.feature_engineering import FeatureEngineer
from backend.ml.training_service import init_training_service, get_training_service


# Connection Manager for WebSocket
class ConnectionManager:
    """Manages active WebSocket connections"""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, user_id: str):
        await websocket.accept()
        self.active_connections[user_id] = websocket
        logger.info(f"User {user_id} connected. Total connections: {len(self.active_connections)}")

    def disconnect(self, user_id: str):
        if user_id in self.active_connections:
            del self.active_connections[user_id]
            logger.info(f"User {user_id} disconnected. Total connections: {len(self.active_connections)}")

    async def send_message(self, user_id: str, message: dict):
        if user_id in self.active_connections:
            await self.active_connections[user_id].send_json(message)

    async def broadcast(self, message: dict):
        for connection in self.active_connections.values():
            await connection.send_json(message)


# Initialize core components
manager = ConnectionManager()
orchestrator = None
memory_manager = None
mongodb_service = None
chromadb_service = None
embedding_service = None
analytics_service = None
feature_engineer = None
training_service = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager"""
    global orchestrator, memory_manager, mongodb_service, chromadb_service, embedding_service, analytics_service, feature_engineer, training_service

    logger.info("ðŸš€ Starting LumenAI...")

    # Initialize MongoDB
    try:
        mongodb_service = init_mongodb_service(
            connection_string=settings.MONGODB_URL,
            database_name=settings.MONGODB_DB_NAME
        )
        await mongodb_service.connect()
        logger.info("âœ… MongoDB connected")
    except Exception as e:
        logger.warning(f"âš ï¸  MongoDB connection failed: {e}. Running without persistence.")
        mongodb_service = None

    # Initialize ChromaDB
    try:
        chromadb_service = init_chromadb_service(
            host=settings.CHROMA_HOST,
            port=settings.CHROMA_PORT
        )
        await chromadb_service.connect()
        logger.info("âœ… ChromaDB connected")
    except Exception as e:
        logger.warning(f"âš ï¸  ChromaDB connection failed: {e}. Running without vector search.")
        chromadb_service = None

    # Initialize Embedding Service
    try:
        if settings.OPENAI_API_KEY:
            embedding_service = init_embedding_service(
                api_key=settings.OPENAI_API_KEY
            )
            logger.info("âœ… Embedding Service initialized")
        else:
            logger.warning("âš ï¸  No OpenAI API key - embeddings disabled")
            embedding_service = None
    except Exception as e:
        logger.warning(f"âš ï¸  Embedding Service failed: {e}")
        embedding_service = None

    # Initialize core systems
    memory_manager = MemoryManager()
    orchestrator = Orchestrator(memory_manager)

    # Initialize Analytics Service (requires all other services)
    try:
        if chromadb_service and embedding_service:
            analytics_service = init_analytics_service(
                llm_engine=orchestrator.llm_engine,
                memory_manager=memory_manager,
                chromadb_service=chromadb_service,
                embedding_service=embedding_service
            )
            logger.info("âœ… Analytics Service initialized")
        else:
            logger.warning("âš ï¸  Analytics Service disabled (requires ChromaDB + Embeddings)")
            analytics_service = None
    except Exception as e:
        logger.warning(f"âš ï¸  Analytics Service failed: {e}")
        analytics_service = None

    # Initialize ML Services (Feature Engineering + Training)
    try:
        feature_engineer = FeatureEngineer(
            memory_manager=memory_manager,
            embedding_service=embedding_service
        )
        logger.info("âœ… Feature Engineer initialized")

        training_service = init_training_service(
            memory_manager=memory_manager,
            feature_engineer=feature_engineer,
            models_dir="backend/ml/models"
        )
        logger.info("âœ… ML Training Service initialized")
    except Exception as e:
        logger.warning(f"âš ï¸  ML Services failed: {e}. Running without ML capabilities.")
        feature_engineer = None
        training_service = None

    logger.info("âœ… LumenAI initialized successfully")

    yield

    # Cleanup
    logger.info("ðŸ›‘ Shutting down LumenAI...")
    if mongodb_service:
        await mongodb_service.disconnect()
        logger.info("âœ… MongoDB disconnected")
    if chromadb_service:
        await chromadb_service.disconnect()
        logger.info("âœ… ChromaDB disconnected")


# Create FastAPI app
app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    lifespan=lifespan
)

# CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Health Check
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "app": settings.APP_NAME,
        "version": settings.APP_VERSION,
        "environment": settings.ENVIRONMENT
    }


# Root endpoint
@app.get("/")
async def root():
    return {
        "message": "ðŸŒŸ Welcome to LumenAI - Your Life Intelligence System",
        "version": settings.APP_VERSION,
        "docs": "/docs"
    }


# WebSocket endpoint for real-time chat
@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    """
    WebSocket endpoint for real-time bidirectional communication
    """
    await manager.connect(websocket, user_id)

    try:
        while True:
            # Receive message from client
            data = await websocket.receive_json()

            logger.info(f"Received from {user_id}: {data}")

            # Extract message content
            message = data.get("message", "")
            message_type = data.get("type", "text")  # text, voice, image
            metadata = data.get("metadata", {})

            # Send typing indicator
            await manager.send_message(user_id, {
                "type": "status",
                "status": "typing"
            })

            # Process through orchestrator
            response = await orchestrator.process_message(
                user_id=user_id,
                message=message,
                message_type=message_type,
                metadata=metadata
            )

            # Send response back to client
            await manager.send_message(user_id, {
                "type": "message",
                "content": response["content"],
                "agent": response.get("agent", "unknown"),
                "metadata": response.get("metadata", {})
            })

    except WebSocketDisconnect:
        manager.disconnect(user_id)
        logger.info(f"Client {user_id} disconnected")
    except Exception as e:
        logger.error(f"Error in WebSocket for {user_id}: {e}")
        manager.disconnect(user_id)


# REST API Endpoints

@app.post("/api/v1/chat")
async def chat(request: dict):
    """
    REST endpoint for chat (alternative to WebSocket)
    """
    try:
        user_id = request.get("user_id")
        message = request.get("message")
        message_type = request.get("type", "text")

        if not user_id or not message:
            raise HTTPException(status_code=400, detail="user_id and message are required")

        response = await orchestrator.process_message(
            user_id=user_id,
            message=message,
            message_type=message_type
        )

        return JSONResponse(content=response)

    except Exception as e:
        logger.error(f"Error in chat endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/user/{user_id}/history")
async def get_user_history(user_id: str, limit: int = 50):
    """Get user's conversation history"""
    try:
        history = await memory_manager.get_user_history(user_id, limit=limit)
        return {"user_id": user_id, "history": history}
    except Exception as e:
        logger.error(f"Error fetching history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/v1/user/{user_id}/memory")
async def clear_user_memory(user_id: str):
    """Clear user's memory (privacy feature)"""
    try:
        await memory_manager.clear_user_memory(user_id)
        return {"status": "success", "message": f"Memory cleared for user {user_id}"}
    except Exception as e:
        logger.error(f"Error clearing memory: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/stats/costs")
async def get_cost_stats():
    """Get LLM API cost statistics"""
    try:
        from backend.core.cost_tracker import cost_tracker
        stats = cost_tracker.get_stats()

        # Add estimated monthly cost
        if stats["total_requests"] > 0:
            stats["estimated_monthly_cost"] = cost_tracker.estimate_monthly_cost(
                requests_per_day=100
            )

        return {
            "status": "success",
            "data": stats,
            "message": f"ðŸ’° Total cost: ${stats['total_cost']:.4f}"
        }
    except Exception as e:
        logger.error(f"Error fetching cost stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# NEW: MongoDB-powered endpoints
# ============================================================================

@app.get("/api/v1/user/{user_id}/conversations")
async def get_user_conversations(user_id: str, limit: int = 20, skip: int = 0):
    """
    Get user's conversations with MongoDB persistence

    NEW FEATURE: Conversations now persist across restarts! ðŸŽ‰
    """
    try:
        db = get_mongodb_service()
        conversations = await db.get_user_conversations(user_id, limit=limit, skip=skip)

        return {
            "status": "success",
            "user_id": user_id,
            "total": len(conversations),
            "conversations": [
                {
                    "conversation_id": conv.conversation_id,
                    "title": conv.title,
                    "started_at": conv.started_at.isoformat(),
                    "last_message_at": conv.last_message_at.isoformat(),
                    "message_count": conv.message_count,
                    "agents_used": conv.agents_used,
                    "status": conv.status
                }
                for conv in conversations
            ]
        }
    except Exception as e:
        logger.error(f"Error fetching conversations: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/conversation/{conversation_id}/messages")
async def get_conversation_messages(conversation_id: str, limit: int = 100):
    """
    Get all messages from a conversation

    NEW FEATURE: Full conversation history from MongoDB! ðŸ’¬
    """
    try:
        db = get_mongodb_service()
        messages = await db.get_conversation_messages(conversation_id, limit=limit)

        return {
            "status": "success",
            "conversation_id": conversation_id,
            "total": len(messages),
            "messages": [
                {
                    "message_id": msg.message_id,
                    "role": msg.role,
                    "content": msg.content,
                    "agent": msg.agent,
                    "timestamp": msg.timestamp.isoformat(),
                    "metadata": {
                        "tokens": msg.metadata.tokens,
                        "cost": msg.metadata.cost,
                        "model": msg.metadata.model
                    }
                }
                for msg in messages
            ]
        }
    except Exception as e:
        logger.error(f"Error fetching messages: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/user/{user_id}/mood/history")
async def get_mood_history(user_id: str, days: int = 7):
    """
    Get user's mood history

    NEW FEATURE: Mood tracking with MongoDB! ðŸ˜Š
    """
    try:
        mood_history = await memory_manager.get_mood_history(user_id, days=days)

        return {
            "status": "success",
            "user_id": user_id,
            "days": days,
            "total_entries": len(mood_history),
            "entries": mood_history
        }
    except Exception as e:
        logger.error(f"Error fetching mood history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/user/{user_id}/mood/stats")
async def get_mood_stats(user_id: str, days: int = 30):
    """
    Get mood statistics and insights

    NEW FEATURE: Analyze mood patterns! ðŸ“Š
    """
    try:
        stats = await memory_manager.get_mood_statistics(user_id, days=days)

        return {
            "status": "success",
            "user_id": user_id,
            "period_days": days,
            "statistics": stats
        }
    except Exception as e:
        logger.error(f"Error fetching mood stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/db/health")
async def database_health():
    """Check MongoDB connection status"""
    try:
        db = get_mongodb_service()
        is_healthy = await db.health_check()

        if is_healthy:
            stats = await db.get_database_stats()
            return {
                "status": "healthy",
                "database": stats.get("database"),
                "collections": stats.get("collections"),
                "total_documents": stats.get("objects")
            }
        else:
            return {
                "status": "unhealthy",
                "message": "MongoDB connection failed"
            }
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        return {
            "status": "error",
            "message": str(e)
        }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=settings.DEBUG
    )

# ============================================================================
# SEMANTIC SEARCH - ChromaDB-powered endpoints
# ============================================================================

@app.post("/api/v1/search/conversations")
async def search_conversations(user_id: str, query: str, n_results: int = 10):
    """
    Semantic search for conversations using ChromaDB.

    Example:
        POST /api/v1/search/conversations
        Body: {"user_id": "user_123", "query": "jak radziÄ‡ sobie ze stresem?", "n_results": 5}

    Response:
        {
            "status": "success",
            "query": "jak radziÄ‡ sobie ze stresem?",
            "total": 5,
            "results": [
                {
                    "content": "...",
                    "similarity": 0.92,
                    "metadata": {...}
                }
            ]
        }
    """
    try:
        results = await memory_manager.search_similar_conversations(
            user_id=user_id,
            query=query,
            n_results=n_results
        )

        return {
            "status": "success",
            "query": query,
            "user_id": user_id,
            "total": len(results),
            "results": results
        }

    except Exception as e:
        logger.error(f"Semantic search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/chromadb/health")
async def chromadb_health():
    """Check ChromaDB connection status and stats"""
    try:
        chromadb = get_chromadb_service()
        embedding_service = get_embedding_service()

        chromadb_status = await chromadb.health_check() if chromadb else False
        chromadb_stats = chromadb.get_stats() if chromadb else {}

        embedding_stats = embedding_service.get_cache_stats() if embedding_service else {}

        return {
            "chromadb": {
                "status": "healthy" if chromadb_status else "unavailable",
                **chromadb_stats
            },
            "embeddings": {
                "status": "available" if embedding_service else "unavailable",
                **embedding_stats
            }
        }

    except Exception as e:
        logger.error(f"ChromaDB health check failed: {e}")
        return {
            "chromadb": {"status": "error", "message": str(e)},
            "embeddings": {"status": "unknown"}
        }


@app.post("/api/v1/embeddings/generate")
async def generate_embedding(text: str):
    """
    Generate embedding for text (utility endpoint for testing).

    Example:
        POST /api/v1/embeddings/generate
        Body: {"text": "Hello world"}

    Response:
        {
            "status": "success",
            "text": "Hello world",
            "embedding": [0.123, -0.456, ...],  # 1536 dimensions
            "dimensions": 1536
        }
    """
    try:
        embedding_service = get_embedding_service()
        if not embedding_service:
            raise HTTPException(status_code=503, detail="Embedding service not available")

        embedding = await embedding_service.generate(text)

        return {
            "status": "success",
            "text": text,
            "embedding": embedding,
            "dimensions": len(embedding)
        }

    except Exception as e:
        logger.error(f"Embedding generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ANALYTICS - Advanced Conversation Analysis
# ============================================================================

@app.post("/api/v1/analytics/conversation/{conversation_id}/summary")
async def summarize_conversation(conversation_id: str, max_length: int = 200):
    """
    Generate automatic conversation summary using LLM.

    Example:
        POST /api/v1/analytics/conversation/conv_123/summary?max_length=150

    Response:
        {
            "status": "success",
            "conversation_id": "conv_123",
            "summary": {
                "summary": "UÅ¼ytkownik rozmawiaÅ‚ o stresie w pracy...",
                "key_topics": ["praca", "stres", "zarzÄ…dzanie czasem"],
                "sentiment": "neutral",
                "action_items": ["SprÃ³buj techniki oddechowej..."],
                "insights": ["Wzrost stresu w ostatnich dniach"]
            }
        }
    """
    try:
        analytics = get_analytics_service()
        if not analytics:
            raise HTTPException(status_code=503, detail="Analytics service not available")

        summary = await analytics.summarize_conversation(
            conversation_id=conversation_id,
            max_length=max_length
        )

        return {
            "status": "success",
            "conversation_id": conversation_id,
            "summary": summary
        }

    except Exception as e:
        logger.error(f"Conversation summarization failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/analytics/user/{user_id}/clusters")
async def get_topic_clusters(user_id: str, n_clusters: int = 5, min_conversations: int = 3):
    """
    Group user's conversations by topics using K-means clustering.

    Example:
        GET /api/v1/analytics/user/user_123/clusters?n_clusters=5

    Response:
        {
            "status": "success",
            "user_id": "user_123",
            "total_clusters": 3,
            "clusters": [
                {
                    "cluster_id": 0,
                    "label": "Praca i kariera",
                    "size": 12,
                    "sample_topics": ["rozmowa kwalifikacyjna", "zarzÄ…dzanie czasem"]
                },
                ...
            ]
        }
    """
    try:
        analytics = get_analytics_service()
        if not analytics:
            raise HTTPException(status_code=503, detail="Analytics service not available")

        clusters = await analytics.cluster_conversations_by_topic(
            user_id=user_id,
            n_clusters=n_clusters,
            min_conversations=min_conversations
        )

        return {
            "status": "success",
            "user_id": user_id,
            "total_clusters": len(clusters["clusters"]),
            "clusters": clusters["clusters"]
        }

    except Exception as e:
        logger.error(f"Topic clustering failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/analytics/user/{user_id}/trends")
async def get_mood_trends(user_id: str, days: int = 30):
    """
    Analyze mood trends over time with statistical analysis.

    Example:
        GET /api/v1/analytics/user/user_123/trends?days=30

    Response:
        {
            "status": "success",
            "user_id": "user_123",
            "period": "30 days",
            "trends": {
                "trend": "improving",  # improving/declining/stable
                "slope": 0.15,
                "statistics": {
                    "average_intensity": 7.2,
                    "volatility": "moderate",
                    "most_common_mood": "happy"
                },
                "data_points": [...],
                "insights": ["Mood improving over last 2 weeks", ...]
            }
        }
    """
    try:
        analytics = get_analytics_service()
        if not analytics:
            raise HTTPException(status_code=503, detail="Analytics service not available")

        trends = await analytics.analyze_mood_trends(
            user_id=user_id,
            days=days
        )

        return {
            "status": "success",
            "user_id": user_id,
            "period": f"{days} days",
            "trends": trends
        }

    except Exception as e:
        logger.error(f"Trend analysis failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/analytics/user/{user_id}/recommendations")
async def get_recommendations(user_id: str, n_recommendations: int = 5):
    """
    Get personalized recommendations based on conversation patterns.

    Example:
        GET /api/v1/analytics/user/user_123/recommendations?n_recommendations=5

    Response:
        {
            "status": "success",
            "user_id": "user_123",
            "total": 5,
            "recommendations": [
                {
                    "type": "topic",
                    "title": "Eksploruj techniki mindfulness",
                    "description": "Na podstawie twoich rozmÃ³w o stresie...",
                    "confidence": 0.85,
                    "source": "topic_clustering"
                },
                {
                    "type": "mood",
                    "title": "RozwaÅ¼ regularne Ä‡wiczenia",
                    "description": "TwÃ³j nastrÃ³j poprawia siÄ™ w dni, gdy wspominasz o aktywnoÅ›ci",
                    "confidence": 0.72,
                    "source": "mood_trends"
                },
                ...
            ]
        }
    """
    try:
        analytics = get_analytics_service()
        if not analytics:
            raise HTTPException(status_code=503, detail="Analytics service not available")

        recommendations = await analytics.get_recommendations(
            user_id=user_id,
            n_recommendations=n_recommendations
        )

        return {
            "status": "success",
            "user_id": user_id,
            "total": len(recommendations["recommendations"]),
            "recommendations": recommendations["recommendations"]
        }

    except Exception as e:
        logger.error(f"Recommendations generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/analytics/health")
async def analytics_health():
    """Check Analytics Service status and dependencies"""
    try:
        analytics = get_analytics_service()

        if not analytics:
            return {
                "status": "unavailable",
                "message": "Analytics service not initialized (requires ChromaDB + Embeddings)"
            }

        # Check all dependencies
        chromadb_ok = await analytics.chromadb.health_check() if analytics.chromadb else False
        embedding_ok = analytics.embeddings is not None

        return {
            "status": "healthy" if (chromadb_ok and embedding_ok) else "degraded",
            "dependencies": {
                "chromadb": "healthy" if chromadb_ok else "unavailable",
                "embeddings": "available" if embedding_ok else "unavailable",
                "llm_engine": "available" if analytics.llm else "unavailable",
                "memory_manager": "available" if analytics.memory else "unavailable"
            },
            "features": {
                "summarization": analytics.llm is not None,
                "clustering": chromadb_ok and embedding_ok,
                "trends": True,  # Only needs MongoDB
                "recommendations": chromadb_ok and embedding_ok
            }
        }

    except Exception as e:
        logger.error(f"Analytics health check failed: {e}")
        return {
            "status": "error",
            "message": str(e)
        }


# ============================================================================
# MACHINE LEARNING - Personalized ML Models
# ============================================================================

@app.post("/api/v1/ml/train/mood-predictor/{user_id}")
async def train_mood_predictor(user_id: str, min_samples: int = 50):
    """
    Trenuje personalizowany model przewidywania nastroju dla uÅ¼ytkownika.

    Model uczy siÄ™ na historycznych danych uÅ¼ytkownika i potrafi przewidzieÄ‡
    przyszÅ‚y nastrÃ³j na podstawie kontekstu rozmowy.

    Example:
        POST /api/v1/ml/train/mood-predictor/user_123?min_samples=50

    Response:
        {
            "success": true,
            "model_type": "mood_predictor",
            "user_id": "user_123",
            "n_samples": 150,
            "metrics": {
                "test_rmse": 1.23,
                "test_mae": 0.98
            },
            "top_features": [...]
        }
    """
    try:
        training = get_training_service()
        if not training:
            raise HTTPException(status_code=503, detail="ML Training Service not available")

        result = await training.train_mood_predictor(
            user_id=user_id,
            min_samples=min_samples
        )

        if not result.get("success"):
            raise HTTPException(status_code=400, detail=result.get("error", "Training failed"))

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Mood predictor training failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ml/train/behavior-profiler/{user_id}")
async def train_behavior_profiler(user_id: str, min_samples: int = 50):
    """
    Trenuje personalizowany model profilowania zachowaÅ„ uÅ¼ytkownika.

    Model klasyfikuje zachowania uÅ¼ytkownika (positive/neutral/negative)
    na podstawie wzorcÃ³w w danych historycznych.

    Example:
        POST /api/v1/ml/train/behavior-profiler/user_123?min_samples=50

    Response:
        {
            "success": true,
            "model_type": "behavior_profiler",
            "user_id": "user_123",
            "n_samples": 150,
            "metrics": {
                "test_accuracy": 0.85,
                "test_f1": 0.82
            },
            "class_distribution": {...}
        }
    """
    try:
        training = get_training_service()
        if not training:
            raise HTTPException(status_code=503, detail="ML Training Service not available")

        result = await training.train_behavior_profiler(
            user_id=user_id,
            min_samples=min_samples
        )

        if not result.get("success"):
            raise HTTPException(status_code=400, detail=result.get("error", "Training failed"))

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Behavior profiler training failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ml/predict/mood")
async def predict_mood(user_id: str, message: str):
    """
    Przewiduje nastrÃ³j uÅ¼ytkownika na podstawie aktualnego kontekstu.

    Wymaga wczeÅ›niej wytrenowanego modelu dla tego uÅ¼ytkownika.

    Example:
        POST /api/v1/ml/predict/mood
        Body: {"user_id": "user_123", "message": "CzujÄ™ siÄ™ dzisiaj Å›wietnie!"}

    Response:
        {
            "status": "success",
            "user_id": "user_123",
            "prediction": {
                "predicted_mood": 8.2,
                "confidence": 0.75,
                "timestamp": "2025-12-03T12:00:00"
            }
        }
    """
    try:
        training = get_training_service()
        if not training:
            raise HTTPException(status_code=503, detail="ML Training Service not available")

        prediction = await training.predict_mood(user_id=user_id, message=message)

        if prediction is None:
            raise HTTPException(
                status_code=404,
                detail=f"No trained mood predictor model found for user {user_id}. Please train first."
            )

        return {
            "status": "success",
            "user_id": user_id,
            "prediction": prediction
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Mood prediction failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ml/predict/behavior")
async def predict_behavior(user_id: str, message: str):
    """
    Klasyfikuje zachowanie uÅ¼ytkownika (positive/neutral/negative).

    Wymaga wczeÅ›niej wytrenowanego modelu dla tego uÅ¼ytkownika.

    Example:
        POST /api/v1/ml/predict/behavior
        Body: {"user_id": "user_123", "message": "Mam problem z pracÄ…"}

    Response:
        {
            "status": "success",
            "user_id": "user_123",
            "prediction": {
                "predicted_class": "negative",
                "probabilities": {
                    "positive": 0.15,
                    "neutral": 0.25,
                    "negative": 0.60
                },
                "timestamp": "2025-12-03T12:00:00"
            }
        }
    """
    try:
        training = get_training_service()
        if not training:
            raise HTTPException(status_code=503, detail="ML Training Service not available")

        prediction = await training.predict_behavior(user_id=user_id, message=message)

        if prediction is None:
            raise HTTPException(
                status_code=404,
                detail=f"No trained behavior profiler model found for user {user_id}. Please train first."
            )

        return {
            "status": "success",
            "user_id": user_id,
            "prediction": prediction
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Behavior prediction failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/ml/model/{user_id}/info")
async def get_model_info(user_id: str, model_type: str = "mood_predictor"):
    """
    Zwraca informacje o wytrenowanym modelu uÅ¼ytkownika.

    Args:
        user_id: ID uÅ¼ytkownika
        model_type: Typ modelu (mood_predictor lub behavior_profiler)

    Example:
        GET /api/v1/ml/model/user_123/info?model_type=mood_predictor

    Response:
        {
            "status": "success",
            "model_info": {
                "model_type": "mood_predictor",
                "trained_at": "2025-12-03T12:00:00",
                "n_samples": 150,
                "metrics": {...}
            }
        }
    """
    try:
        training = get_training_service()
        if not training:
            raise HTTPException(status_code=503, detail="ML Training Service not available")

        info = training.get_model_info(user_id, model_type)

        if info is None:
            raise HTTPException(
                status_code=404,
                detail=f"No {model_type} model found for user {user_id}"
            )

        return {
            "status": "success",
            "model_info": info
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Get model info failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/ml/health")
async def ml_health():
    """Check ML Services status"""
    try:
        training = get_training_service()
        feature_eng = feature_engineer

        return {
            "status": "healthy" if (training and feature_eng) else "unavailable",
            "services": {
                "feature_engineer": "available" if feature_eng else "unavailable",
                "training_service": "available" if training else "unavailable"
            },
            "capabilities": {
                "mood_prediction": training is not None,
                "behavior_profiling": training is not None,
                "feature_extraction": feature_eng is not None
            }
        }

    except Exception as e:
        logger.error(f"ML health check failed: {e}")
        return {
            "status": "error",
            "message": str(e)
        }

